{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d8c433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## choose 'print' or 'manuscript'\n",
    "book_type = 'manuscript'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d16d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import math\n",
    "from prayer_leiden import *\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01031fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All books\n",
    "json_file = open(f'{book_type}_books.json')\n",
    "json_data = json.load(json_file)\n",
    "titles = json_data['titles']\n",
    "book_texts = json_data['book_texts']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff96658",
   "metadata": {},
   "source": [
    "## Frequencies of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b49f4fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272 books\n",
      "1459 unique texts\n"
     ]
    }
   ],
   "source": [
    "total_nr_texts = 0\n",
    "\n",
    "# total number of texts\n",
    "text_freq = Counter()\n",
    "\n",
    "for book in book_texts:\n",
    "    texts = book_texts[book]\n",
    "    text_freq.update(texts)\n",
    "\n",
    "print(f\"{len(book_texts)} books\")\n",
    "print(f\"{len(text_freq)} unique texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a29e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4085 witnesses/expressions in total\n",
      "512 of texts which have a frequency of 2 or more\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum(text_freq.values())} witnesses/expressions in total\")\n",
    "corpus = []\n",
    "\n",
    "for text,count in text_freq.most_common():\n",
    "    if count>1:\n",
    "        corpus.append(text)\n",
    "        \n",
    "total_nr_texts = len(corpus)\n",
    "print(f\"{total_nr_texts} of texts which have a frequency of 2 or more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ebbb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947 texts occur only once.\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(text_freq)-total_nr_texts} texts occur only once.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e1efa5",
   "metadata": {},
   "source": [
    "## Co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934f3f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 512/512 [00:22<00:00, 22.94it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rows = []\n",
    "\n",
    "for text in tqdm(corpus):\n",
    "    row = []\n",
    "    row.append(text)\n",
    "    \n",
    "    for text2 in corpus:\n",
    "        nr_cooccurrences = 0\n",
    "        for book in book_texts:\n",
    "            texts = book_texts[book]\n",
    "            if text in texts and text2 in texts:\n",
    "                nr_cooccurrences += 1\n",
    "        row.append(nr_cooccurrences/total_nr_texts)\n",
    "    rows.append(row)\n",
    "    \n",
    "columns = ['text']\n",
    "columns.extend(corpus)\n",
    "\n",
    "joint_probability  = pd.DataFrame(rows,columns=columns)\n",
    "joint_probability = joint_probability.set_index('text')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f04d3",
   "metadata": {},
   "source": [
    "## Text probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff5336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = dict()\n",
    "\n",
    "for text in corpus:\n",
    "    probability[text] = text_freq[text]/total_nr_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26097225",
   "metadata": {},
   "source": [
    "## Pointwise Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32a4c961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 512/512 [00:11<00:00, 43.89it/s]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for text1 in tqdm(corpus):\n",
    "    row = []\n",
    "    row.append(text1)\n",
    "    \n",
    "    for text2 in corpus:\n",
    "        jp_texts = joint_probability.loc[text1][text2]\n",
    "        jp_texts = math.pow(jp_texts, 1.7)\n",
    "        if (jp_texts/(probability[text1]*probability[text2]))>0:\n",
    "            pmi = math.log2((jp_texts/(probability[text1]*probability[text2])))\n",
    "        else:\n",
    "            pmi = 0\n",
    "        pmi = (jp_texts/(probability[text1]*probability[text2]))\n",
    "\n",
    "        row.append(pmi)\n",
    "    rows.append(row)\n",
    "    \n",
    "columns = ['text']\n",
    "columns.extend(corpus)\n",
    "\n",
    "pmi_df = pd.DataFrame(rows,columns=columns)\n",
    "pmi_df = pmi_df.set_index('text')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7092ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████▏                      | 212/512 [31:20<1:29:23, 17.88s/it]"
     ]
    }
   ],
   "source": [
    "max_cluster_length = 15\n",
    "\n",
    "all_clusters = []\n",
    "\n",
    "for text in tqdm(corpus):\n",
    "    pmi_dict = pmi_df.loc[text].sort_values(ascending=False).to_dict()\n",
    "    \n",
    "    texts = []\n",
    "    for high_association in pmi_dict:\n",
    "        if pmi_dict[high_association] > 0:\n",
    "            texts.append(high_association)\n",
    "            \n",
    "    if len(texts)>max_cluster_length:\n",
    "        texts = texts[:max_cluster_length]\n",
    "\n",
    "    nr_texts = len(texts)\n",
    "\n",
    "    while nr_texts>2:\n",
    "\n",
    "        clusters = all_combinations(texts,nr_texts)\n",
    "        all_clusters.extend(clusters)\n",
    "        all_clusters = deduplicate_list(all_clusters)\n",
    "        #all_clusters = remove_subsets(all_clusters)\n",
    "        nr_texts = nr_texts-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c234c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_clusters2 = remove_subsets(all_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'all_clusters_{book_type}.csv','w',encoding='utf-8') as out:\n",
    "    \n",
    "    out.write('cluster,length,frequency\\n')\n",
    "\n",
    "    for cluster in tqdm(all_clusters):\n",
    "        #print(cluster)\n",
    "        row = dict()\n",
    "        books = find_books_containing_cluster(cluster,book_texts)\n",
    "        row['cluster'] = ' '.join(str(x) for x in cluster)\n",
    "        row['length'] = len(cluster)\n",
    "        row['frequency'] = len(books)\n",
    "        if row['frequency']>=2:\n",
    "            out.write(f\"{row['cluster']},{row['length']},{row['frequency']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
